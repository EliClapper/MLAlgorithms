
a single neuron is a linear combination of some input vector multiplied by a weight vector.
the neuron itself has a bias/intercept. The neuron below can be either a hidden layer neuron or an output neuron. It takes input from 3 input neurons we can come from the input layer or a hidden layer. Note, that we, theoretically, would have to estimate 4 parameters: 1 bias and 3 weights. For now we treat them as known.
```{r}
X <- c(1,4,2)
weights <- c(0.4, 1.1, -0.3)
bias <- 1.3

output <- bias + X[1]*weights[1] + X[2]*weights[2] + X[3]*weights[3] 
print(output)

```


Lets code a layer which contains 3 neurons with 4 inputs. The input is the same for all neurons, but they assign different weights and they have different biases. The output now is a vector of 3 values, but every neuron is still a linear combination of the output of the previous layer. Also note that this one layer already needs estimation of 15 parameters: 3 biases, 3*4 = 12 weights
```{r}
X <- c(1, 4, 2, 0.5)
weights1 <- c(0.4, 1.1, -0.3, -2)
weights2 <- c(1, 0.4, -2.1, -1)
weights3 <- c(0.2, 0.1, 2.2, -0.5)
bias1 <- 1.3
bias2 <- 1.4
bias3 <- 0.3

output <- c(bias1 + X[1]*weights1[1] + X[2]*weights1[2] + X[3]*weights1[3] + X[4]*weights1[4],
            bias2 + X[1]*weights2[1] + X[2]*weights2[2] + X[3]*weights2[3] + X[4]*weights2[4],
            bias3 + X[1]*weights3[1] + X[2]*weights3[2] + X[3]*weights3[3] + X[4]*weights3[4])
print(output)


```

The code above can be optimized, but very difficult to do with only for loops and lists as you can see below, altough it does show how it works later on.
```{r}
X <- c(1, 4, 2, 0.5)
weights <- list(c(0.4, 1.1, -0.3, -2), c(1, 0.4, -2.1, -1), c(0.2, 0.1, 2.2, -0.5))
bias <- c(1.3, 1.4, 0.3)

lincomb <- c() #memory
#for loop below creates a vector of 3*4 = 12 elements, of which the sum of every 4 elements is the dot product of X with a particular vector in weights.
for(i in seq_along(weights)){
  for(j in seq_along(X)){
    slopes <- X[j]*weights[[i]][j]
    lincomb <- append(lincomb, slopes)
  }
}

lincomb <- unname(tapply(lincomb, (seq_along(lincomb)-1) %/% 4, sum)) #this takes the sum over every 4 elements of the list.

layer_output <- c() #memory
#here we sum the biases and dot products to obtain 3 outputs, each from one neuron
for(i in seq_along(bias)){
  neuron_output <- bias[i] + lincomb[i]
  layer_output <- append(layer_output, neuron_output)
}
print(layer_output)




```

lets try it with matrix algebra which makes it a million times more efficient
```{r}
X <- c(1, 4, 2, 0.5) #vector
weights <- cbind(c(0.4, 1.1, -0.3, -2), c(1, 0.4, -2.1, -1), c(0.2, 0.1, 2.2, -0.5)) #instead of a list, we create a matrix
bias <- c(1.3, 1.4, 0.3) #vector

layer_output <- bias + X%*%weights #this used dot product of X with every column of weights and we add the bias
print(layer_output)

```

